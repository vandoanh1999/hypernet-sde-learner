# Hypernet-SDE-Flow: Má»™t Kiáº¿n TrÃºc Há»c LiÃªn Tá»¥c (Continual Learning) Äá»™t PhÃ¡
## [Vandoanh Van](https://github.com/vandoanh1999)

[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/get-started/locally/)
![Tests](https://github.com/vandoanh1999/hypernet-sde-learner/workflows/tests/badge.svg)
![Code Coverage](https://codecov.io/gh/vandoanh1999/hypernet-sde-learner/branch/main/graph/badge.svg)

`Hypernet-SDE-Flow` lÃ  má»™t kiáº¿n trÃºc AI thá»­ nghiá»‡m (experimental) Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t má»™t trong nhá»¯ng thÃ¡ch thá»©c lá»›n nháº¥t cá»§a TrÃ­ Tuá»‡ NhÃ¢n Táº¡o hiá»‡n Ä‘áº¡i: **Sá»± QuÃªn LÃ£ng Tháº£m Khá»‘c (Catastrophic Forgetting)**.

Dá»± Ã¡n nÃ y chá»©ng minh kháº£ nÄƒng cho phÃ©p má»™t mÃ´ hÃ¬nh há»c liÃªn tiáº¿p nhiá»u tÃ¡c vá»¥ (tasks) mÃ  **khÃ´ng cáº§n huáº¥n luyá»‡n láº¡i (retrain)** trÃªn dá»¯ liá»‡u cÅ©. Äiá»u nÃ y má»Ÿ ra con Ä‘Æ°á»ng cho cÃ¡c há»‡ thá»‘ng AI cÃ³ kháº£ nÄƒng há»c táº­p suá»‘t Ä‘á»i (Lifelong Learning) thá»±c sá»±, tiáº¿t kiá»‡m Ä‘Ã¡ng ká»ƒ chi phÃ­ tÃ­nh toÃ¡n vÃ  tÃ i nguyÃªn.

---

## ğŸš€ Äiá»ƒm Nháº¥n ChÃ­nh & Chá»©ng Minh Äá»™t PhÃ¡

**Váº¥n Ä‘á»:** CÃ¡c mÃ´ hÃ¬nh AI truyá»n thá»‘ng "quÃªn" hoÃ n toÃ n tÃ¡c vá»¥ cÅ© khi há»c tÃ¡c vá»¥ má»›i. Äiá»u nÃ y cáº£n trá»Ÿ sá»± phÃ¡t triá»ƒn cá»§a AI cÃ³ thá»ƒ thÃ­ch nghi liÃªn tá»¥c.
**Giáº£i phÃ¡p:** `Hypernet-SDE-Flow` sá»­ dá»¥ng sá»± káº¿t há»£p Ä‘á»™c Ä‘Ã¡o cá»§a Hypernetworks, Stochastic Differential Equations (SDEs), vÃ  Normalizing Flows Ä‘á»ƒ báº£o tá»“n tri thá»©c qua cÃ¡c tÃ¡c vá»¥ mÃ  khÃ´ng cáº§n replay toÃ n bá»™ dá»¯ liá»‡u.

Má»™t hÃ¬nh áº£nh giÃ¡ trá»‹ hÆ¡n 1000 dÃ²ng chá»¯. Äá»“ thá»‹ dÆ°á»›i Ä‘Ã¢y minh há»a káº¿t quáº£ benchmark trÃªn 5 tÃ¡c vá»¥ há»c liÃªn tá»¥c.

**Káº¿t quáº£:** MÃ´ hÃ¬nh `Hypernet-SDE-Flow` (mÃ u xanh lÃ¡) **duy trÃ¬ hiá»‡u suáº¥t khÃ´ng Ä‘á»•i** trÃªn tÃ¡c vá»¥ Ä‘áº§u tiÃªn (`Task 0`) ngay cáº£ sau khi há»c 4 tÃ¡c vá»¥ má»›i. Trong khi Ä‘Ã³, `Baseline MLP` (mÃ u Ä‘á») **quÃªn gáº§n nhÆ° hoÃ n toÃ n** `Task 0` sau khi há»c tÃ¡c vá»¥ tiáº¿p theo.

http://googleusercontent.com/generated_image_content/0

`

**Giáº£i thÃ­ch:**

  * **Trá»¥c Y (log scale):** Lá»—i TÃ¡i Táº¡o (MSE Loss) trÃªn `Task 0`. GiÃ¡ trá»‹ cÃ ng tháº¥p cÃ ng tá»‘t.
  * **Trá»¥c X:** TÃ¡c vá»¥ `T_i` vá»«a hoÃ n thÃ nh viá»‡c há»c.
  * **Chá»‰ sá»‘ Forgetting (QuÃªn lÃ£ng):**
      * `Hypernet-SDE-Flow`: **~0.0035** (Gáº§n báº±ng 0, cho tháº¥y khÃ´ng quÃªn)
      * `Baseline MLP`: **~2.0512** (Cá»±c cao, cho tháº¥y quÃªn hoÃ n toÃ n)

---

## ğŸ”¬ SÃ¢u HÆ¡n Vá» Kiáº¿n TrÃºc: Bá»™ Ba Äá»™t PhÃ¡

`Hypernet-SDE-Flow` khai thÃ¡c sá»©c máº¡nh cá»§a ba khÃ¡i niá»‡m toÃ¡n há»c vÃ  há»c sÃ¢u tiÃªn tiáº¿n:

### 1\. Hypernetwork: Bá»™ NÃ£o Sinh Trá»ng Sá»‘ Äá»™ng

Thay vÃ¬ má»™t táº­p há»£p trá»ng sá»‘ cá»‘ Ä‘á»‹nh, má»™t `Hypernetwork` sáº½ **sinh ra cÃ¡c trá»ng sá»‘ (weights)** cá»¥ thá»ƒ cho tá»«ng tÃ¡c vá»¥ (`W_task`). Äiá»u nÃ y giÃºp cÃ´ láº­p kiáº¿n thá»©c cá»§a tá»«ng tÃ¡c vá»¥, ngÄƒn cháº·n sá»± ghi Ä‘Ã¨ vÃ  quÃªn lÃ£ng.

* **TÃ­nh nÄƒng:** Dynamic Weight Generation, Task-Specific Adaptation.
* **Lá»£i Ã­ch:** TrÃ¡nh Catastrophic Forgetting báº±ng cÃ¡ch Ä‘áº£m báº£o cÃ¡c tÃ¡c vá»¥ khÃ´ng can thiá»‡p vÃ o nhau á»Ÿ cáº¥p Ä‘á»™ tham sá»‘.

### 2\. Neural Stochastic Differential Equations (Neural SDEs): MÃ´ HÃ¬nh HÃ³a Äá»™ng Lá»±c Há»c Ngáº«u NhiÃªn

`Neural SDEs` mÃ´ hÃ¬nh hÃ³a cÃ¡c quÃ¡ trÃ¬nh Ä‘á»™ng há»c cá»§a dá»¯ liá»‡u trong khÃ´ng gian tiá»m áº©n (latent space) dÆ°á»›i dáº¡ng cÃ¡c quÃ¡ trÃ¬nh ngáº«u nhiÃªn.
$$dZ = f(Z, t)dt + g(Z, t)dW_t$$
Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh náº¯m báº¯t sá»± phá»©c táº¡p vÃ  báº¥t Ä‘á»‹nh (uncertainty) cá»‘ há»¯u cá»§a dá»¯ liá»‡u, táº¡o ra cÃ¡c biá»ƒu diá»…n phong phÃº vÃ  máº¡nh máº½ hÆ¡n nhiá»u so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tÄ©nh.

* **TÃ­nh nÄƒng:** Probabilistic Dynamics, Robust Representation Learning.
* **Lá»£i Ã­ch:** Xá»­ lÃ½ tá»‘t hÆ¡n dá»¯ liá»‡u cÃ³ nhiá»…u, táº¡o ra cÃ¡c biá»ƒu diá»…n Ä‘a dáº¡ng vÃ  cÃ³ Ã½ nghÄ©a thá»‘ng kÃª.

### 3\. Manifold Normalizing Flows: Biáº¿n Äá»•i KhÃ´ng Gian Tiá»m áº¨n

`Normalizing Flows` lÃ  má»™t chuá»—i cÃ¡c phÃ©p biáº¿n Ä‘á»•i kháº£ nghá»‹ch (invertible transformations) giÃºp Ã¡nh xáº¡ má»™t phÃ¢n phá»‘i phá»©c táº¡p (dá»¯ liá»‡u) vá» má»™t phÃ¢n phá»‘i Ä‘Æ¡n giáº£n (vÃ­ dá»¥: Gaussian chuáº©n).
$$Z \xrightarrow{f} U \sim \mathcal{N}(0, I)$$
Äiá»u nÃ y cho phÃ©p chÃºng ta tÃ­nh toÃ¡n chÃ­nh xÃ¡c xÃ¡c suáº¥t log (log-likelihood) cá»§a dá»¯ liá»‡u, cung cáº¥p má»™t tiÃªu chÃ­ huáº¥n luyá»‡n máº¡nh máº½ hÆ¡n cho viá»‡c há»c cÃ¡c biá»ƒu diá»…n dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao.

* **TÃ­nh nÄƒng:** Exact Likelihood Computation, Complex Distribution Modeling.
* **Lá»£i Ã­ch:** Äáº£m báº£o biá»ƒu diá»…n tiá»m áº©n cÃ³ cáº¥u trÃºc toÃ¡n há»c cháº·t cháº½, cáº£i thiá»‡n cháº¥t lÆ°á»£ng tÃ¡i táº¡o vÃ  sinh dá»¯ liá»‡u.

---

# Quick start - 3 dÃ²ng Ä‘á»ƒ cháº¡y
git clone https://github.com/vandoanh1999/hypernet-sde-learner.git
cd hypernet-sde-learner && pip install -r requirements.txt
python benchmark_compare.py --tasks 5 --epochs 100

---

## ğŸ› ï¸ HÆ°á»›ng Dáº«n Nhanh: TÃ¡i Táº¡o Káº¿t Quáº£ 

Tá»± mÃ¬nh cháº¡y benchmark vÃ  kiá»ƒm chá»©ng hiá»‡u suáº¥t Ä‘á»™t phÃ¡.

### 1\. CÃ i Äáº·t MÃ´i TrÆ°á»ng

Äáº£m báº£o báº¡n cÃ³ Python 3.9+ vÃ  cÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t. Dá»± Ã¡n nÃ y táº­n dá»¥ng `torch.compile` (PyTorch 2.0+) Ä‘á»ƒ tá»‘i Æ°u hiá»‡u suáº¥t.

```bash
# 1. Clone repo tá»« GitHub
git clone [https://github.com/vandoanh1999/hypernet-sde-learner.git](https://github.com/vandoanh1999/hypernet-sde-learner.git)
cd hypernet-sde-learner

# 2. CÃ i Ä‘áº·t cÃ¡c Dependencies (bao gá»“m PyTorch, TorchSDE, Matplotlib)
pip install -r requirements.txt


---
